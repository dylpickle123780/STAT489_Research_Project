---
title: "Fair Market Rent Difference: A Pattern Analysis of Unfair Housing Prices"
format:
  arxiv-pdf:
    keep-tex: true  
    linenumbers: false
    doublespacing: false
    runninghead: "A Preprint"
  arxiv-html: default
author:
  - name: Dylan Michaels
    affiliations:
      - name: Texas A&M University 
        department: Statistics
        address: 1 400 Bizzell St
        city: College Station, TX
        country: USA
        postal-code: 77843
    email: dmichaels54321@tamu.edu
  - name: Shouro Shuvit
    affiliations:
      - name: Texas A&M University
        department: Statistics
        address: 1 400 Bizzell St
        city: College Station, TX
        country: USA
        postal-code: 77843
    email: shouroshuvit@tamu.edu
abstract: |
  The fair market rent (FMR) system in the United States is used by the Department of Housing to ascertain what housing should cost in any given county based on economic factors, however reality often does not reflect this estimate as other factors push the cost of housing higher. Fair Market Rent Difference is an analysis technique that leverages Random Forests in order to find where in the United States there is a large difference between the FMR and the actual market rent. With Random Forests, we are able to accurately create a predictive field that shows these disparities and what areas they are formed in. The analysis will allow for a broad overlook of how housing unaffordability fluctuates with respect to space when it is compared to a price point that is based on the economic data of the county. This analysis can be a baseline for future research into market conditions that drive regions of the US to have tighter housing demands than expected by the government to then enact policy for housing affordability in unsuspecting places.

keywords: 
  - template
  - demo
bibliography: bibliography.bib  
---

# Introduction {#sec-intro}

The United States is infamous for its housing unaffordability crisis with over half of American Renters unable to afford rent according to the Joint Center for Housing Studies at Harvard University however with the government allocating 72.6 Billion dollars to be spent in 2025 for the Department of Housing and Urban Development with an additional 185 billion dollars to be spent to solve the housing crisis over the next ten years, there has to be a way to allocate the funds to maximize people being able to afford their rent. 

We believe that the Fair Market Rent system (FMR) that the government is using can be improved upon to incorporate live housing stock data to make better inferences on where in the United States housing unaffordability is. 

Currently the Fair Market Rent system relies on a multitude of factors which mainly includes economic factors like household wealth and GDP per capita within counties to find a 40th percentile price for what can be affordable housing for 60% of the population within a certain area. This system will then allocate housing units at those determined prices to push down the price of rent in those markets or allow for vouchers to be used to live in those areas. The main issue that is found is that market rent can vary wildly from year to year for reasons other than the economic well being of the community (FMR paper). 

With this research, we aim to bridge the gap between the the actual market rent and the FMR data provided by the government to portray an accurate picture of the real estate market and see what parts of the market are actually affordable 



Thesis
A metric that compares the difference between market rent and Fair Market Rent can capture more housing unaffordability data than either data set can do alone. 


# Related Works
Paper on Random forests (Breiman) overviewing method
How random forests work in general and brief overview of the randomness factor that is associated with them

Need for accounting for spatial structure (Fuss)
Impact of space on housing in general 

Paper on random forests and apartment rent (Yoshida)
Explain how breiman’s method is especially useful for apartment data because of their large sample sizes

# Methods
We used a UCI Machine learning apartment dataset (UCI machine learning). Most data points from 2018-2019 period. Only analyzed the contiguous United States and removed some observations that were missing data. This translated to removing ~40 observations out of 52,000. From the histogram of price we decided to log transform the price to make it more normally distributed.
```{r, message=FALSE, results = "hide", cache=TRUE, warning=FALSE}
source("../Analysis/EDA_file_100k.R")
par(mfrow = c(1,2))
hist(apartments_100k_cleaned$price,main = "Histogram of Price", xlab = "Price")
hist(log(apartments_100k_cleaned$price), main = "Histogram of Log(Price)", xlab = "Log(Price)")
```
\
Next we decided that we would convert this point data into county level data. This allowed us to add population as a covariate and also the number of observations in each county as a proxy for how active the renting environment is in each county. For number of bathrooms and bedrooms we took the median of all observations in the county and for square footage we took the mean square footage of the observations. Once aggregated into county level data we were left with roughly 1000 observations of counties out of the 3109 counties in the contiguous United States. 
```{r, message=FALSE, results = "hide", cache=TRUE, warning=FALSE}
source("../Analysis/Point_To_Areal.R")
ggplot(joined_data)+
  geom_sf(aes(fill = price))+
  scale_fill_gradientn(colours = terrain.colors(8))
```

We used Department of Housing’s Fair market rent data from 2019 and also log transformed the pricing (FMR citation). There were roughly 4,400 observations accounting for rent areas across the United States. 

Geographically weighted regression (GWR) is a method of accounting for spatialy varying covariates in a linear regression model (Brundson et al). Go lightly into detail about GWR including model assumptions. Transition sentence into simulation study. 

To verify that GWR was an appropriate choice for our data we performed a simulation study that utilized voronoi tessellation to create an artificial spatial area. We ordered the polygons according to their x coordinate in order to get a smooth surface from which we could generate proper coefficients for our covariates. 
```{r, message=FALSE, results = "hide", cache=TRUE, warning=FALSE}
source("../Simulation/GWR_simulation.R")
ggplot(voronoi_polys)+
  geom_sf(aes(fill = num))+
  scale_fill_viridis_c()
```
We modeled coefficients by generating sequences that roughly matched with the scale of coefficients that we would see with our real data. Go into specific parameters used along with generation of values. 

We use GWR as a comparison because we know rent is spatially varying (Fuss) and want a statistical model that can give us interpretable coefficients for our covariates. The two most important hyperparameters when fitting a GWR model are the kernel and bandwidth. We decided to use an exponential kernel due to how sharp some of the changes are along the coastline and around the Denver, Colorado area [cross reference to EDA above]. We estimated the bandwidth using cross validation and came upon [bandwidth] as the best fit. 

We used XGboost and Random forests for their predictive power and their effectiveness in predicting rent pricing has been seen in (Yoshida). Go into random forests (Breiman) and justify these two as best algorithmic models to compare to using (Yoshida) and (Seya). We optimized hyperparameters using k-fold validation to come upon the best values to be used. 

We compared GWR, Random Forests, and XGboost on predicting and modeling out of sample observations using mean absolute error (MAE), root mean squared error (RMSE), and mean squared error (MSE).


# Results
Plots with our final predictive surface are coming in the next day or two. 

Table showing that the out of sample error (MSE, RMSE, MAE) was similar across all 3 models.

Choosing Random Forest due to its predictive power.

# Discussion
We found that in (select locations and POIs later) probably going to be Denver, Dallas, and College Station. There is an unexpected difference between these urban areas and their surrounding counties. We theorize it is because of (discuss reason here). These policies and geographic constraints lead to the results we are seeing in these areas. 

When we see why these results are occurring we can look to the covariates of Bedroom, Bathroom, and SQFT which come from the 100k Dataset to see what is causing these differences

We also have to be considerate of our high p values which are unnaturally high because of the log transform. Once we transformed it back to raw prices the p values drop dramatically. 

As expected though the urban coasts are far more unfair compared to the FMR data.

We can use the metric to assess where in the US is deemed unfair. We can also see where funding can be reallocated from areas where the housing costs are lower than the FMR value 




# Citations

This section of the template is adapted from the [Quarto citation documentation](https://quarto.org/docs/authoring/footnotes-and-citations.html).

Quarto supports bibliography files in a wide variety of formats including BibTeX and CSL. Add a bibliography to your document using the `bibliography` YAML metadata field. For example:

``` yaml
---
title: "My Document"
bibliography: references.bib
---
```

See the [Pandoc Citations](https://pandoc.org/MANUAL.html#citations) documentation for additional information on bibliography formats.

## Citation Syntax {#sec-citations}

Quarto uses the standard Pandoc markdown representation for citations. Here are some examples:

+---------------------------------------+-------------------------------------------------------------------+
| Markdown Format                       | Output                                                            |
+=======================================+===================================================================+
| ```                                   | Blah Blah [see @knuth1984, pp. 33-35; also @wickham2015, chap. 1] |
| Blah Blah [see @knuth1984, pp. 33-35; |                                                                   |
| also @wickham2015, chap. 1]           |                                                                   |
| ```                                   |                                                                   |
+---------------------------------------+-------------------------------------------------------------------+
| ```                                   | Blah Blah [@knuth1984, pp. 33-35, 38-39 and passim]               |
| Blah Blah [@knuth1984, pp. 33-35,     |                                                                   |
| 38-39 and passim]                     |                                                                   |
| ```                                   |                                                                   |
+---------------------------------------+-------------------------------------------------------------------+
| ```                                   | Blah Blah [@wickham2015; @knuth1984].                             |
| Blah Blah [@wickham2015; @knuth1984]. |                                                                   |
| ```                                   |                                                                   |
+---------------------------------------+-------------------------------------------------------------------+
| ```                                   | Wickham says blah [-@wickham2015]                                 |
| Wickham says blah [-@wickham2015]     |                                                                   |
| ```                                   |                                                                   |
+---------------------------------------+-------------------------------------------------------------------+

You can also write in-text citations, as follows:

+-------------------------------+-------------------------------+
| Markdown Format               | Output                        |
+===============================+===============================+
| ```                           | @knuth1984 says blah.         |
| @knuth1984 says blah.         |                               |
| ```                           |                               |
+-------------------------------+-------------------------------+
| ```                           | @knuth1984 [p. 33] says blah. |
| @knuth1984 [p. 33] says blah. |                               |
| ```                           |                               |
+-------------------------------+-------------------------------+

See the [Pandoc Citations](https://pandoc.org/MANUAL.html#citations) documentation for additional information on citation syntax.

To provide a custom citation stylesheet, provide a path to a CSL file using the `csl` metadata field in your document, for example:

``` yaml
---
title: "My Document"
bibliography: references.bib
csl: nature.csl
---
```

{{< pagebreak >}}

# References {.unnumbered}

::: {#refs}
:::
